<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Nakul Sharma</title>

    <meta name="author" content="Nakul Sharma">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Nakul Sharma
                </p>
                <p>
		I'm a Research Engineer at <a href="https://spreeai.com/">SpreeAI</a>, where I work on developing new training schemes and architectures for virtual try-on using diffusion and flow-based models in close collaboration with <a href="https://aayushbansal.xyz">Dr. Aayush Bansal</a> and <a href="https://minhpvo.github.io/">Dr. Minh Vo</a>.
		Prior to that, I completed my Bachelor's in Technology in AI and Data Science at <a href="https://www.iitj.ac.in/">IIT Jodhpur</a> in 2024. At IIT Jodhpur, I was fortunate to be a part of <a href="https://anandmishra22.github.io/">Prof. Anand Mishra</a>'s <a href="https://vl2g.github.io/">Vision, Language and Learning Group (VL2G)</a>, where I worked on 2D generative models, representation learning and multi-modal LLMs.
                </p>
                <p style="text-align:center">
                  <a href="mailto:0xnakul.sh@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="data/Nakul_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=8EsVX1kAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/0xnakul/">GitHub</a>
                </p>
              </td>
              <td style="padding:1.5%;width:37%;max-width:37%;">
                <a href="images/nakul-mntry.webp"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 20%;" alt="profile photo" src="images/nakul-mntry.webp" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm broadly interested in improving representation learning for various downstream tasks, and multi-modal generative modeling.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <!--<tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
      </span>
        </a>
        <br>
				<a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr>-->


    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle; text-align:center">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="data/papers/sharma2025efficient.pdf">
          <span class="papertitle">	Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data</span>
        </a>
        <br>
          <strong>Nakul Sharma</strong>
        <br>
        <em>ICCV 2025 Workshop on Curated Data and Efficient Learning</em>
        <br>
        <!--<a href="https://vl2g.github.io/projects/PatentLMM/">project page</a>
        /
        <a href="https://arxiv.org/abs/2501.15074">arXiv</a>
        /
        <a href="https://docs.google.com/presentation/d/1-qw2VucHJcxCHzc6upy4dwOyPFujEodpc3s2pGnnL0s/edit?slide=id.p#slide=id.p">slides</a>
        /
        <a href="https://github.com/vl2g/PatentLMM">code & dataset</a>-->
        <a href="data/papers/sharma2025efficient.pdf">paper</a>
        <p></p>
        <p>This preliminary study introduces a lighweight way to utilize strong semantuc representations of strong visual foundation models for the long-tail recognition.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle; text-align:center">
        <img src="images/patentlmm-illstr.png" alt="PatentMME" width="260" height="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://vl2g.github.io/projects/PatentLMM/">
          <span class="papertitle">PatentLMM: Large Multimodal Model for Generating Descriptions for Patent Figures</span>
        </a>
        <br>
          Shreya Shukla*,
          <strong>Nakul Sharma</strong>*,
          <a href="https://sites.google.com/view/manishg/">Manish Gupta</a>,
          <a href="https://anandmishra22.github.io/">Anand Mishra </a>
        <br>
        <em>AAAI</em>, 2025
        <br />(*: equal contribution)
        <br>
        <a href="https://vl2g.github.io/projects/PatentLMM/">project page</a>
        /
        <a href="https://arxiv.org/abs/2501.15074">arXiv</a>
        /
        <a href="https://docs.google.com/presentation/d/1-qw2VucHJcxCHzc6upy4dwOyPFujEodpc3s2pGnnL0s/edit?slide=id.p#slide=id.p">slides</a>
        /
        <a href="https://github.com/vl2g/PatentLMM">code & dataset</a>
        <p></p>
        <p>We curate the first large-scale dataset for the task; current models perform poorly due to their visual representations and therefore, we propose to train a weakly supervised visual encoder, PatentMME, using which PatentLMM surpasses GPT-4V significantly. </p>
      </td>
    </tr>
  
    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle; text-align:center">
        <img src="images/skinp-hr.png" alt="Sketch-guided image inpainting" width="320" height="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/html/Sharma_Sketch-guided_Image_Inpainting_with_Partial_Discrete_Diffusion_Process_CVPRW_2024_paper.html">
          <span class="papertitle">Sketch-guided Image Inpainting with Partial Discrete Diffusion Process</span>
        </a>
        <br>
          <strong>Nakul Sharma</strong>,
          <a href="https://iiscaditaytripathi.github.io/">Aditay Tripathi</a>,
          <a href="https://anirbanchakraborty.github.io/">Anirban Chakraborty</a>,
          <a href="https://anandmishra22.github.io/">Anand Mishra </a>
        <br>
        <em>CVPR-W</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2404.11949">arXiv</a>
        /
        <a href="https://docs.google.com/presentation/d/14tR8-vwIrhrbexoD1C4PvjZvFDqg-gV-ADg3rB253Y8/edit?usp=sharing">slides</a>
        /
        <a href="https://github.com/vl2g/Sketch-Inpainting">code</a>
        <p></p>

        <p>We propose Partial Discrete Diffusion Process for sketch-guided inpainting, wherein only regions of interest are corrupted during the forward process &#8212; aligning the forward process and the reverse process for inpainting.</p>
      </td>
    </tr>

    <tr>
      <td style="padding:16px;width:20%;vertical-align:middle; text-align:center">
        <img src="images/logo-ident-teaser.png" alt="clean-usnob" width="200" height="160">
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://vl2g.github.io/projects/logoIdent/">
          <span class="papertitle">Contrastive Multi-View Textual-Visual Encoding: Towards One Hundred Thousand-Scale One-Shot Logo Identification</span>
        </a>
        <br>
          <strong>Nakul Sharma</strong>,
          Abhirama Subramanyam Penamakuri,
          <a href="https://anandmishra22.github.io/">Anand Mishra </a>
        <br>
        <em>ICVGIP</em> 2022
        <br>
        <a href="https://vl2g.github.io/projects/logoIdent/">project page</a>
        /
        <a href="https://arxiv.org/abs/2211.12926">arXiv</a>
        /
        <a href="https://docs.google.com/presentation/d/1f3FDtjDLgr2y6cky2o-aVPUvAjicisPD4V5xyaiN3Hg/edit?slide=id.g1a0b337e560_0_0#slide=id.g1a0b337e560_0_0">slides</a>
        /
        <a href="https://github.com/thisis-nkul/one-shot-logo_icvgip">code</a>
        /
        <a href="https://github.com/Abhiram4572/LogoIdent">data</a>
        <p></p>
        <p>We study the problem of identifying logos in an open-set setting and propose a to encode textual and visual information from logos, along with a better contrastive loss.</p>
      </td>
    </tr>

    </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #c6b89e;">
								 <h2>Academic Service</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                Reviewer for CVPR: 2025
                <br>
                Reviewer for ACL ARR: 2025, 2024
              </td>
            </tr>
						
						
           
            <tr>
              <td align="center" style="padding:16px;width:20%;vertical-align:middle">
						     <div class="colored-box" style="background-color: #edd892;">
								 <h2>Teaching</h2>
								 </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:center">
                Teaching Assistant for CSL 2010: Introduction to Machine Learning, taught by <a href="https://sites.google.com/view/yashaswiverma/">Prof. Yashaswi Verma</a> at <a href="https://iitj.ac.in/">IIT Jodhpur</a>, Fall 2022.
              </td>
            </tr>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br><br><br>
                <p style="text-align:right;font-size:small;">
                  This website template was ethically stolen from <a href="https://jonbarron.info/">Jon Barron</a>. 
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
